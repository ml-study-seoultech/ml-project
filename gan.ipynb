{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/500 [00:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 110\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# 손실 계산\u001b[39;00m\n\u001b[1;32m    109\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(inpainted, inputs) \u001b[38;5;241m+\u001b[39m criterion(colorized, targets)\n\u001b[0;32m--> 110\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    113\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_py38/lib/python3.8/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_py38/lib/python3.8/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_py38/lib/python3.8/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# 1. 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, input_dir, gt_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.input_dir = input_dir\n",
    "        self.gt_dir = gt_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path = os.path.join(self.input_dir, self.data.iloc[idx]['input_image_path'])\n",
    "        gt_path = os.path.join(self.gt_dir, self.data.iloc[idx]['gt_image_path'])\n",
    "\n",
    "        # 이미지 로드\n",
    "        input_image = Image.open(input_path).convert('L')  # 흑백\n",
    "        gt_image = Image.open(gt_path).convert('RGB')  # 컬러\n",
    "\n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "            gt_image = self.transform(gt_image)\n",
    "\n",
    "        return input_image, gt_image\n",
    "\n",
    "# 2. 데이터 전처리 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # [-1, 1] 정규화\n",
    "])\n",
    "\n",
    "# 3. 데이터셋 및 데이터로더 생성\n",
    "train_dataset = ImageDataset(\n",
    "    csv_file='./train.csv',\n",
    "    input_dir='',\n",
    "    gt_dir='',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# 4. 모델 정의\n",
    "class FullPipeline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mask_model = smp.Unet(\n",
    "            encoder_name=\"resnet34\",        \n",
    "            encoder_weights=\"imagenet\",     \n",
    "            in_channels=1,                  \n",
    "            classes=1                       \n",
    "        )\n",
    "        self.inpaint_model = smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=2,  # 이미지 + 마스크\n",
    "            classes=1\n",
    "        )\n",
    "        self.colorize_model = smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=1,\n",
    "            classes=3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1: Mask Detection\n",
    "        mask = self.mask_model(x)\n",
    "        \n",
    "        # Step 2: Inpainting\n",
    "        input_with_mask = torch.cat([x, mask], dim=1)  # 채널 합치기\n",
    "        inpainted = self.inpaint_model(input_with_mask)\n",
    "        \n",
    "        # Step 3: Colorization\n",
    "        colorized = self.colorize_model(inpainted)\n",
    "        \n",
    "        return mask, inpainted, colorized\n",
    "\n",
    "# 5. 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FullPipeline().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "# 6. 학습 루프\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 예측\n",
    "        mask, inpainted, colorized = model(inputs)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(inpainted, inputs) + criterion(colorized, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def test_model(model, test_csv, input_dir, transform, save_dir):\n",
    "    # 테스트 데이터셋 생성\n",
    "    test_data = pd.read_csv(test_csv)\n",
    "    input_paths = test_data[\"input_image_path\"]\n",
    "\n",
    "    model.eval()  # 모델 평가 모드\n",
    "    os.makedirs(save_dir, exist_ok=True)  # 결과 저장 디렉토리 생성\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, input_path in enumerate(input_paths):\n",
    "            # 입력 이미지 로드 및 전처리\n",
    "            full_input_path = os.path.join(input_dir, input_path)\n",
    "            input_image = Image.open(full_input_path).convert(\"L\")  # 흑백\n",
    "            input_tensor = (\n",
    "                transform(input_image).unsqueeze(0).to(device)\n",
    "            )  # 배치 차원 추가\n",
    "\n",
    "            # 모델 예측\n",
    "            _, _, colorized = model(input_tensor)\n",
    "\n",
    "            # 결과를 numpy 형식으로 변환\n",
    "            output_np = colorized[0].cpu().permute(1, 2, 0).numpy()  # 컬러화된 결과\n",
    "\n",
    "            # 이미지 범위 복구 (Normalize 후 값 범위 복원)\n",
    "            output_np = (\n",
    "                (output_np * 255).clip(0, 255).astype(\"uint8\")\n",
    "            )  # 0-255로 스케일링\n",
    "\n",
    "            # 파일명 설정 (TEST_000, TEST_001, ...)\n",
    "            save_path = os.path.join(save_dir, f\"TEST_{idx:03d}.png\")\n",
    "            Image.fromarray(output_np).save(save_path)\n",
    "\n",
    "            print(f\"Result saved to: {save_path}\")\n",
    "\n",
    "\n",
    "# 8. 테스트 실행\n",
    "test_csv = \"./test.csv\"  # 테스트 CSV 파일 경로\n",
    "input_dir = \"./test_inputs\"  # 테스트 입력 이미지 디렉토리\n",
    "save_dir = \"./sample_submission\"  # 결과 저장 디렉토리\n",
    "\n",
    "test_model(model, test_csv, input_dir, transform, save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
